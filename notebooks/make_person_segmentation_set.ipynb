{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> Add person image sets
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "DATASET_BASE = '../data/VOCdevkit/VOC2012'\n",
    "IMAGE_SET_DIR = f'{DATASET_BASE}/ImageSets/Segmentation'\n",
    "IMAGE_DIR = f'{DATASET_BASE}/SegmentationClass'\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 13,
>>>>>>> Add person image sets
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = pd.read_table(f'{IMAGE_SET_DIR}/train.txt', squeeze=True)\n",
    "val_filenames = pd.read_table(f'{IMAGE_SET_DIR}/train.txt', squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 15,
>>>>>>> Add person image sets
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_class(filename, _class=15, threshold=0.1):\n",
    "    im = Image.open(f'{IMAGE_DIR}/{filename}.png')\n",
    "    im = np.array(im)\n",
    "    num_class = im[im == _class].size\n",
    "    num_total = im.size\n",
    "    return (num_class / num_total) >= 0.1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 18,
>>>>>>> Add person image sets
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_filenames = train_filenames[train_filenames.map(contains_class)]\n",
    "filtered_val_filenames = val_filenames[val_filenames.map(contains_class)]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 21,
>>>>>>> Add person image sets
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_filenames = pd.concat([filtered_train_filenames, filtered_val_filenames])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 27,
>>>>>>> Add person image sets
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cutoff = int(combined_filenames.size * 0.8)\n",
    "combined_filenames[0:val_cutoff].to_csv(f'{IMAGE_SET_DIR}/person_train.txt', index=False)\n",
    "combined_filenames[val_cutoff:].to_csv(f'{IMAGE_SET_DIR}/person_val.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = pd.read_table('../VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt')\n",
    "valid_filenames = pd.read_table(''../VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt)"
   ]
  }
 ]
}