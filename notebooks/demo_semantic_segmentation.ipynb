{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import decode_segmap, display_image, get_best_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use eval to enable prediction mode for the model\n",
    "device = get_best_device()\n",
    "model = torchvision.models.segmentation.fcn_resnet101(pretrained=True)\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_filename = '../data/VOCdevkit/VOC2012/JPEGImages/2007_001299.jpg'\n",
    "image = Image.open(original_filename)\n",
    "\n",
    "print(\"Image shape:\", (image.width, image.height))\n",
    "\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.Compose([      \n",
    "    transforms.CenterCrop((380, 380)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transformed_image = transform_pipeline(image)\n",
    "transformed_image = torch.unsqueeze(transformed_image, dim=0)\n",
    "transformed_image = transformed_image.to(device)\n",
    "\n",
    "print(\"Transformed image shape:\", transformed_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(transformed_image)['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract masks\n",
    "mask = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
    "mask = decode_segmap(mask)\n",
    "\n",
    "display_image(mask)\n",
    "\n",
    "true_mask = Image.open('../data/VOCdevkit/VOC2012/SegmentationClass/2007_001299.png')\n",
    "true_mask = transforms.CenterCrop((380, 380))(true_mask)\n",
    "display_image(true_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}